{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_DCGANs_CIFAR10_multi_tpu.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2930341092c74954919ff5f57a627fcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fd4c031ed4bd421a86dec4781f7f8e29",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0540992f13654221b335bdfee56df795",
              "IPY_MODEL_7ec12e3e2a3a40c6866622f3bd31ed79"
            ]
          }
        },
        "fd4c031ed4bd421a86dec4781f7f8e29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0540992f13654221b335bdfee56df795": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0c8cd744ed2745d58ad53d7d77dc6a08",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9fc0ee90ffa1469d8173c7c85c568874"
          }
        },
        "7ec12e3e2a3a40c6866622f3bd31ed79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2ada8ea777944ecdb92c613e1a5fdedb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [1:16:40&lt;00:00, 37064.34it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e4a19e269bb64baab99a11fd9ea7caca"
          }
        },
        "0c8cd744ed2745d58ad53d7d77dc6a08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9fc0ee90ffa1469d8173c7c85c568874": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2ada8ea777944ecdb92c613e1a5fdedb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e4a19e269bb64baab99a11fd9ea7caca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdRroa4nkOwg"
      },
      "source": [
        "!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.7-cp36-cp36m-linux_x86_64.whl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2HuwKGIki1v"
      },
      "source": [
        "!pip3 install jupyterthemes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BB2AdAB3klA-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c41042a-321a-43da-9b29-f0e18a0be807"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "from torchsummary import summary\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "import os\n",
        "import sys\n",
        "from datetime import datetime\n",
        "from tqdm.notebook import tqdm\n",
        "from jupyterthemes import jtplot\n",
        "jtplot.style(theme=\"monokai\", context=\"notebook\", ticks=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Waiting for TPU to be start up with version pytorch-1.7...\n",
            "WARNING:root:Waiting for TPU to be start up with version pytorch-1.7...\n",
            "WARNING:root:TPU has started up successfully with version pytorch-1.7\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z73ZjSwQlrs5"
      },
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(), \n",
        "    transforms.Normalize(mean=(0.5, ), std=(0.5, )),\n",
        "    transforms.Resize((64, 64))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJEqN5OPmI3y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "2930341092c74954919ff5f57a627fcd",
            "fd4c031ed4bd421a86dec4781f7f8e29",
            "0540992f13654221b335bdfee56df795",
            "7ec12e3e2a3a40c6866622f3bd31ed79",
            "0c8cd744ed2745d58ad53d7d77dc6a08",
            "9fc0ee90ffa1469d8173c7c85c568874",
            "2ada8ea777944ecdb92c613e1a5fdedb",
            "e4a19e269bb64baab99a11fd9ea7caca"
          ]
        },
        "outputId": "2373d2e2-29ad-44a6-b6ee-74e2f756cca2"
      },
      "source": [
        "train_data = torchvision.datasets.CIFAR10(root=\"./DATA/\", transform=transform, download=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./DATA/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2930341092c74954919ff5f57a627fcd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./DATA/cifar-10-python.tar.gz to ./DATA/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0-21ajQmXTl"
      },
      "source": [
        "def get_discriminator_block(input_channel, output_channel, kernel_size=3,\n",
        "                            stride=2, padding=0, final_layer=False, batchNorm=True):\n",
        "    \n",
        "    \"\"\"\n",
        "    Description : Function to build the discriminator neural block\n",
        "\n",
        "    Parameters:\n",
        "    @param input_channel -- a python integer representing the input channel\n",
        "    @param output_channel -- a python integer representing the output channel\n",
        "    @param kernel_size -- a python integer representing the kernel size (by default=3)\n",
        "    @param stride -- a python integer representing the stride (by default=2)\n",
        "    @param padding -- a python integer representing the padding (by default=0)\n",
        "    @param final_layer -- boolean value representing whether it is the last layer (by default=False)\n",
        "    @param batchNorm -- boolean value representing whether to apply batchNorm or not (by default=True)\n",
        "\n",
        "    Return:\n",
        "    @ret disc_block -- A sequential neural block\n",
        "    \"\"\"\n",
        "\n",
        "    disc_block = None\n",
        "\n",
        "    if not final_layer and batchNorm:\n",
        "        disc_block = nn.Sequential(\n",
        "            nn.Conv2d(input_channel, output_channel, kernel_size=kernel_size, stride=stride, padding=padding, bias=False),\n",
        "            nn.BatchNorm2d(output_channel),\n",
        "            nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
        "        )\n",
        "\n",
        "    elif not batchNorm and not final_layer:\n",
        "        disc_block = nn.Sequential(\n",
        "            nn.Conv2d(input_channel, output_channel, kernel_size=kernel_size, stride=stride, padding=padding, bias=False),\n",
        "            nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
        "        )\n",
        "\n",
        "    else:\n",
        "        disc_block = nn.Sequential(\n",
        "            nn.Conv2d(input_channel, output_channel, kernel_size=kernel_size, stride=stride, padding=padding, bias=False)\n",
        "        )\n",
        "\n",
        "    return disc_block\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRxJF1bOup8E"
      },
      "source": [
        "def get_generator_block(input_channel, output_channel, kernel_size=3, stride=2,\n",
        "                        padding=0, final_layer=False):\n",
        "    \n",
        "    \"\"\"\n",
        "    Description : Function to create the generator neural block\n",
        "\n",
        "    Parameters:\n",
        "    @param input_channel -- a python integer representing the input channel\n",
        "    @param output_channel -- a python integer representing the output channel\n",
        "    @param kernel_size -- a python integer representing the kernel size (by default=3)\n",
        "    @param stride -- a python integer representing the stride value (by default=2)\n",
        "    @param padding -- a python integer representing the padding value (by default=0)\n",
        "    @param final_layer -- a boolean value representing whether it is the final layer or not (by default=False)\n",
        "\n",
        "    Return:\n",
        "    @ret gen_block -- a Sequential neural block\n",
        "    \"\"\"\n",
        "\n",
        "    gen_block = None\n",
        "\n",
        "    if not final_layer:\n",
        "        gen_block = nn.Sequential(\n",
        "            nn.ConvTranspose2d(input_channel, output_channel, kernel_size=kernel_size, stride=stride, padding=padding, bias=False),\n",
        "            nn.BatchNorm2d(output_channel),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    else:\n",
        "        gen_block = nn.Sequential(\n",
        "            nn.ConvTranspose2d(input_channel, output_channel, kernel_size=kernel_size, stride=stride, padding=padding, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    return gen_block"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbNxFRJIxIJt"
      },
      "source": [
        "def get_noise(batch_size, latent_dim, device):\n",
        "    \"\"\"\n",
        "    Description : Function to generate noise \n",
        "\n",
        "    Parameters : \n",
        "    @param batch_size -- the batch size for the noise\n",
        "    @param latent_dim -- the dimension for the noise\n",
        "    @param device -- the device to transfer to\n",
        "\n",
        "    Return :\n",
        "    @ret noise -- the noise value for the current batch size \n",
        "    \"\"\"\n",
        "\n",
        "    noise = torch.randn(batch_size, latent_dim, device=device)\n",
        "    return noise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63gK-7_jyfPB"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_channel, hidden_channel=64):\n",
        "\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.disc = nn.Sequential(\n",
        "            get_discriminator_block(input_channel, hidden_channel, kernel_size=4, stride=2, padding=1, batchNorm=False),\n",
        "            get_discriminator_block(hidden_channel, hidden_channel*2, kernel_size=4, stride=2, padding=1),\n",
        "            get_discriminator_block(hidden_channel*2, hidden_channel*4, kernel_size=4, stride=2, padding=1),\n",
        "            get_discriminator_block(hidden_channel*4, hidden_channel*8, kernel_size=4, stride=2, padding=1),\n",
        "            get_discriminator_block(hidden_channel*8, 1, kernel_size=4, stride=1, padding=0, final_layer=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, X):\n",
        "        return self.disc(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdklSFmx359Q"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "\n",
        "    def __init__(self, latent_dim, im_channels=3, hidden_channel=64):\n",
        "\n",
        "        super(Generator, self).__init__()\n",
        "        \n",
        "        self.latent_dim = latent_dim\n",
        "        self.gen = nn.Sequential(\n",
        "            get_generator_block(latent_dim, hidden_channel*8, kernel_size=4, stride=1, padding=0),\n",
        "            get_generator_block(hidden_channel*8, hidden_channel*4, kernel_size=4, stride=2, padding=1),\n",
        "            get_generator_block(hidden_channel*4, hidden_channel*2, kernel_size=4, stride=2, padding=1),\n",
        "            get_generator_block(hidden_channel*2, hidden_channel, kernel_size=4, stride=2, padding=1),\n",
        "            get_generator_block(hidden_channel, im_channels, kernel_size=4, stride=2, padding=1, final_layer=True)\n",
        "        )\n",
        "\n",
        "    def unsqueeze_noise(self, noise):\n",
        "        return noise.view(len(noise), self.latent_dim, 1, 1)\n",
        "\n",
        "    def forward(self, noise):\n",
        "        noise = self.unsqueeze_noise(noise)\n",
        "        return self.gen(noise)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98LPvJQY6Br-"
      },
      "source": [
        "def get_discriminator_loss(G, D, criterion, real_data, latent_dim, batch_size, device):\n",
        "\n",
        "    \"\"\"\n",
        "    Description : Function to calculate the loss of the discriminator\n",
        "\n",
        "    Parameters:\n",
        "    @param G : the Generator network\n",
        "    @param D : the Discriminator network\n",
        "    @param real_data : the images \n",
        "    @param criterion : the loss function \n",
        "    @param latent_dim : the latent dimension for the noise vector\n",
        "    @param batch_size : the batch_size \n",
        "    @param device : the device to transfer to\n",
        "\n",
        "    Return:\n",
        "    @ret disc_loss : the Discriminator Loss\n",
        "    \"\"\"\n",
        "\n",
        "    real_pred = D(real_data)\n",
        "    ones_ = torch.ones_like(real_pred).to(device)\n",
        "    real_loss = criterion(real_pred, ones_)\n",
        "\n",
        "    noise = get_noise(batch_size, latent_dim, device)\n",
        "    fake_img = G(noise).detach()\n",
        "    fake_pred = D(fake_img)\n",
        "    zeros_ = torch.zeros_like(fake_pred).to(device)\n",
        "    fake_loss = criterion(fake_pred, zeros_)\n",
        "\n",
        "    disc_loss = 0.5 * (fake_loss + real_loss)\n",
        "\n",
        "    return disc_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJGb9g6sGNYY"
      },
      "source": [
        "def get_generator_loss(G, D, criterion, latent_dim, batch_size, device):\n",
        "\n",
        "    \"\"\"\n",
        "    Description : Function to calculate the loss of the generator\n",
        "\n",
        "    Parameters:\n",
        "    @param G : the Generator network\n",
        "    @param D : the Discriminator network\n",
        "    @param criterion : the loss function \n",
        "    @param latent_dim : the latent dimension for the noise vector\n",
        "    @param batch_size : the batch_size \n",
        "    @param device : the device to transfer to\n",
        "\n",
        "    Return:\n",
        "    @ret gen_loss : the Discriminator Loss\n",
        "    \"\"\"\n",
        "\n",
        "    noise = get_noise(batch_size, latent_dim, device)\n",
        "    fake_img = G(noise)\n",
        "    fake_pred = D(fake_img)\n",
        "    ones_ = torch.ones_like(fake_pred).to(device)\n",
        "    gen_loss = criterion(fake_pred, ones_)\n",
        "    return gen_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqnCDAEcMj4_"
      },
      "source": [
        "def init_weight(m):\n",
        "\n",
        "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
        "        torch.nn.init.normal_(m.weight, mean = 0.0, std=0.02)\n",
        "\n",
        "    if isinstance(m, nn.BatchNorm2d):\n",
        "        torch.nn.init.normal_(m.weight, mean=0.0, std=0.02)\n",
        "        torch.nn.init.normal_(m.weight, mean=0.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Clv0NUUsHvgT"
      },
      "source": [
        "def train(index, flags):\n",
        "    \n",
        "    g_losses = []\n",
        "    d_losses = []\n",
        "\n",
        "    torch.manual_seed(flags['seed'])\n",
        "\n",
        "    device = xm.xla_device()\n",
        "\n",
        "    dataset = flags['dataset']\n",
        "\n",
        "    sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "        dataset, \n",
        "        num_replicas = xm.xrt_world_size(),\n",
        "        rank = xm.get_ordinal(),\n",
        "        shuffle = True\n",
        "    )\n",
        "\n",
        "    data_loader = torch.utils.data.DataLoader(\n",
        "        dataset, \n",
        "        batch_size = flags['batch_size'],\n",
        "        sampler = sampler,\n",
        "        num_workers = flags['num_workers'],\n",
        "        drop_last = True\n",
        "    )\n",
        "\n",
        "    G = Generator(flags['latent_dim'])\n",
        "    D = Discriminator(flags['color_channel'])\n",
        "    \n",
        "    # print(\"========== Summary of the Generator ============\")\n",
        "    # print(summary(G, (100, )))\n",
        "\n",
        "    # print(\"------------- Summary of the Discriminator -------------\")\n",
        "    # print(summary(D, (3, 64, 64)))\n",
        "\n",
        "    G = G.to(device)\n",
        "    D = D.to(device)\n",
        "\n",
        "    G = G.apply(init_weight)\n",
        "    D = D.apply(init_weight)\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    g_optim = torch.optim.Adam(G.parameters(), lr=1e-4 * 4, betas = (0.5, 0.999))\n",
        "    d_optim = torch.optim.Adam(D.parameters(), lr=1e-4 * 2, betas = (0.5, 0.999))\n",
        "\n",
        "    for epoch in range(flags['epochs']):\n",
        "\n",
        "        para_loader = pl.ParallelLoader(data_loader, [device]).per_device_loader(device)\n",
        "        t0 = datetime.now()\n",
        "        g_loss = []\n",
        "        d_loss = []\n",
        "        batch_size = 0\n",
        "        for batch in tqdm(para_loader):\n",
        "\n",
        "            data, _ = batch\n",
        "\n",
        "            data = data.to(device)\n",
        "\n",
        "            batch_size = data.size(0)\n",
        "\n",
        "            ####################################\n",
        "            ###### TRAIN DISCRIMINATOR #########\n",
        "            #####################################\n",
        "            d_optim.zero_grad()\n",
        "            dLoss = get_discriminator_loss(G, D, criterion, data, \n",
        "                                           flags['latent_dim'], batch_size, device)\n",
        "            \n",
        "            dLoss.backward()\n",
        "            xm.optimizer_step(d_optim)\n",
        "\n",
        "            d_loss.append(dLoss.item())\n",
        "\n",
        "            #######################################\n",
        "            ############ TRAIN GENERATOR ##########\n",
        "            #######################################\n",
        "\n",
        "            g_optim.zero_grad()\n",
        "            gLoss = get_generator_loss(G, D, criterion, \n",
        "                                       flags['latent_dim'], batch_size, device)\n",
        "            \n",
        "            gLoss.backward()\n",
        "            xm.optimizer_step(g_optim)\n",
        "\n",
        "            g_loss.append(gLoss.item())\n",
        "\n",
        "        \n",
        "        g_loss = np.mean(g_loss)\n",
        "        d_loss = np.mean(d_loss)\n",
        "\n",
        "        g_losses.append(g_loss)\n",
        "        d_losses.append(d_loss)\n",
        "\n",
        "        print(f\"Epoch : {epoch+1}/{flags['epochs']} || Disc Loss : {d_loss} || Gen Loss : {g_loss} || Time elapsed : {datetime.now() - t0} || Process : {index}\")\n",
        "\n",
        "        if flags['save'] and (epoch+1) % 10 == 0:\n",
        "            noise = get_noise(batch_size, flags['latent_dim'], device)\n",
        "            fake_img = G(noise).detach()\n",
        "            save_image(fake_img, f\"./DCGANS_CIFAR10_multi_tpu/gan_{epoch + 1}_index_{index}.png\", normalize=True)\n",
        "\n",
        "    \n",
        "    return G, D, g_losses, d_losses\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0v1CM6HFPFrs"
      },
      "source": [
        "if not os.path.exists(\"./DCGANS_CIFAR10_multi_tpu/\"):\n",
        "    os.mkdir(\"./DCGANS_CIFAR10_multi_tpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgQZ6DwrQWVt"
      },
      "source": [
        "flags = {\n",
        "    \"num_workers\" : 8,\n",
        "    \"batch_size\" : 128,\n",
        "    \"epochs\" : 200,\n",
        "    \"latent_dim\" : 100,\n",
        "    \"color_channel\" : 3,\n",
        "    \"seed\" : 1234,\n",
        "    \"dataset\" : train_data,\n",
        "    \"save\" : True\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3C1B7cKwQ2L5"
      },
      "source": [
        "G, D, g_losses, d_losses = xmp.spawn(train, args=(flags, ), nprocs=8, start_method='fork')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "An4C2D3WVV7F"
      },
      "source": [
        "!zip -r \"images.zip\" ./DCGANS_CIFAR10_multi_tpu/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78gnKirYViW3"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"images.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8U5F2Ii-Vqrg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}